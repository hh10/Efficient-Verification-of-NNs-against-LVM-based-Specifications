{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d809dd82",
   "metadata": {},
   "source": [
    "### This notebook prepares EDC pipelines vs SRVP pipelines for different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d40422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 300\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# set random seed for reproducibility.\n",
    "seed = 1123\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "print(\"Random Seed: \", seed)\n",
    "\n",
    "# use GPU if available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device, \"will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247cddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [3,64,64]\n",
    "batch_size = 6\n",
    "batch_input_shape = [batch_size, *input_shape]\n",
    "\n",
    "classes = [\"Male\"]\n",
    "num_classes = len(classes) + 1\n",
    "\n",
    "latent_dims = 32\n",
    "\n",
    "## loading vs running params\n",
    "# set False and set params in the EDCs preparation section below if want to train the EDCs.\n",
    "edc_load = True  \n",
    "# set False if want to train the classifier in the Classifier preparation section below.\n",
    "cla_load = True  \n",
    "# set False and set params in the SRVPs preparation section below if want to train the SRVPs.\n",
    "srvp_load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cbd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset preparation\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from notebook_utils import CelebADataset, flog\n",
    "from utils import get_transforms\n",
    "\n",
    "dset = CelebADataset(\"../data/CelebA\", \"list_attr_celeba.txt\", get_transforms(input_shape[-1], [], True), classes)\n",
    "data_len, test_ratio = len(dset), 0.1\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dset, [int(np.ceil((1-test_ratio)*data_len)), int(np.floor(test_ratio*data_len))]\n",
    ")\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617e7b9",
   "metadata": {},
   "source": [
    "### Encoder->Decoder->Classifier (EDC) pipelines preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30616cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EDC pipelines summary and reconstruction statistics\n",
    "from notebook_utils import get_encoder, Encoder, GenModel, get_decoder#, test_gen_model\n",
    "from utils import denormalize\n",
    "\n",
    "exp_disc = \"baseline\"\n",
    "edc_dir = f\"./models/gen_models_{input_shape[-1]}/EDC_{latent_dims}/{exp_disc}\"\n",
    "os.makedirs(edc_dir, exist_ok=True)\n",
    "\n",
    "dec_types = [\"tiny\", \"small\", \"deeper\", \"resnet\"]\n",
    "edc_gens = {}\n",
    "for edc_dec_type in dec_types:\n",
    "    # test_gen_model(\"big\", edc_dec_type, batch_input_shape, latent_dims)\n",
    "    dec = get_decoder(edc_dec_type, input_shape, latent_dims)\n",
    "    edc_gens[edc_dec_type] = GenModel(Encoder(get_encoder(\"big\", input_shape, latent_dims), device), \n",
    "                                      dec,\n",
    "                                      device,\n",
    "                                      f\"{edc_dir}/enc_big_edc_{edc_dec_type}.tar\" if edc_load else None)\n",
    "    if not edc_load:\n",
    "        flog(f\"{edc_dir}/notes.txt\", [edc_dec_type, dec, summary(dec, input_size=(1, latent_dims), device=device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb11574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDC trainings code\n",
    "if not edc_load:\n",
    "    from notebook_utils import train_gen_model\n",
    "\n",
    "    dec_types = [\"tiny\", \"small\", \"deeper\", \"resnet\"]\n",
    "    nepochs = {\"tiny\": 6, \"small\": 8, \"deeper\": 12, \"resnet\": 18}\n",
    "    for dec_type in dec_types:\n",
    "        print(f\"Training EDC with Encoder: big, Decoder: {dec_type}.\")\n",
    "        edc_gen = edc_gens[dec_type]\n",
    "        opt_gen = torch.optim.Adam(edc_gen.parameters(), lr=2.5e-3)\n",
    "        gen_path = f\"{edc_dir}/enc_big_edc_{dec_type}\"\n",
    "        edc_gens[dec_type] = train_gen_model(edc_gen, opt_gen, gen_path, train_dl, num_epochs=nepochs[dec_type], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import denormalize, save_batch_images # for FID score computation using 3rd party lib\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# reconstruction checks measures on decoders\n",
    "edc_fig = f\"{edc_dir}/figures\"\n",
    "os.makedirs(edc_fig, exist_ok=True)\n",
    "\n",
    "recons_errs = {k: [] for k in dec_types}\n",
    "for bi, (x, y) in enumerate(train_dl):\n",
    "    save_image(make_grid(denormalize(\"CelebA\", x[:32])), f\"{edc_fig}/original_{bi}.png\")\n",
    "    save_batch_images(denormalize(\"CelebA\", x), f\"{edc_fig}/original\", bi)\n",
    "    for dec_type in dec_types:\n",
    "        x_hat = torch.clamp(edc_gens[dec_type](x.to(device))[-1], min=-1, max=1).cpu()\n",
    "        recons_errs[dec_type].append(torch.nn.MSELoss()(x_hat, x).item()) #(torch.sqrt(torch.sum((x-x_hat)**2))/N).item())\n",
    "        save_image(make_grid(denormalize(\"CelebA\", x_hat[:32])), f\"{edc_fig}/enc_big_{dec_type}_{bi}.png\")\n",
    "        save_batch_images(denormalize(\"CelebA\", x_hat), f\"{edc_fig}/dec_{dec_type}\", bi)\n",
    "    if bi > 20:\n",
    "        break\n",
    "\n",
    "print(\"Reconstruction errors\")\n",
    "for k, v in recons_errs.items():\n",
    "    v = np.array(v)\n",
    "    print(k, np.min(v), np.mean(v), np.median(v), np.max(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7663d",
   "metadata": {},
   "source": [
    "### Classifiers (Networks) preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873add37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import get_classifier, train_cla, test_cla\n",
    "\n",
    "cla_type = \"deeper\"\n",
    "cla_path = f\"./models/classifiers_{input_shape[-1]}/{cla_type}_{classes[0]}\"\n",
    "cla = get_classifier(cla_type, latent_dims, num_classes, device, f\"{cla_path}.tar\" if cla_load else None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbd9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLA training code\n",
    "if not cla_load:\n",
    "    os.makedirs(os.path.dirname(cla_path), exist_ok=True)\n",
    "     cla = train_cla(cla, cla_path, train_dl, num_epochs=6, device=device)\n",
    "flog(f\"{cla_path}_notes.txt\", [summary(cla, input_size=(1, *input_shape), device=device), f\"Test accuracy: {test_cla(cla, train_dl, device)}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab4150",
   "metadata": {},
   "source": [
    "### Semantic Robustness Verification Problem (SRVP) pipelines preparation for the above Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import build_srvp_pipeline\n",
    "\n",
    "srvp_disc = \"baseline\"\n",
    "srvp_dir = f\"./models/SRVP_{input_shape[-1]}/cla_{cla_type}\"\n",
    "srvps = {32: None, 64: None, 192: None, 392: None}\n",
    "scla_loads = {32: False, 64: False, 192: False, 392: True, 512: False}\n",
    "lds = [32, 64, 192, 392]\n",
    "for ld in lds: \n",
    "    cla = get_classifier(cla_type, latent_dims, num_classes, device, f\"{cla_path}.tar\" if scla_loads[ld] else None)\n",
    "    srvp_path = f\"{srvp_dir}/ld{ld}\"\n",
    "    srvps[ld], _ = build_srvp_pipeline(device, cla, input_shape, ld, \"deeper\", f\"{srvp_path}.tar\" if srvp_load else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461f2cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training SRVP pipeline\n",
    "if not srvp_load:\n",
    "    from notebook_utils import train_gen_model, train_gen_model_all\n",
    "\n",
    "    for ld in lds:\n",
    "        if scla_loads[ld]:\n",
    "            gen_params = list(srvp.encoding_head.parameters()) + list(srvp.decoder.parameters())\n",
    "        else:\n",
    "            gen_params = list(srvp.parameters())\n",
    "        opt_gen = torch.optim.Adam(gen_params, lr=5e-4)\n",
    "        srvps[ld] = train_gen_model_all(srvp, opt_gen, srvp_path, train_dl, num_epochs=12, device=device, with_cla=not scla_loads[ld])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04fe14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import denormalize, save_batch_images # for FID score computation using 3rd party lib\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# save SRVPs recons in a folder for FID\n",
    "srvp_fig = f\"{srvp_dir}/figures\"\n",
    "os.makedirs(srvp_fig, exist_ok=True)\n",
    "\n",
    "recons_errs = {k: [] for k in lds}\n",
    "for bi, (x, y) in enumerate(train_dl):\n",
    "    save_image(make_grid(denormalize(\"CelebA\", x[:32])), f\"{srvp_fig}/original_{bi}.png\")\n",
    "    save_batch_images(denormalize(\"CelebA\", x), f\"{srvp_fig}/original\", bi)\n",
    "    for ld in lds:\n",
    "        x_out = srvps[ld](x.to(device))\n",
    "        x_hat = torch.clamp(x_out[-1], min=-1, max=1).cpu()\n",
    "        recons_errs[ld].append(torch.nn.MSELoss()(x_hat, x).item())\n",
    "        save_image(make_grid(denormalize(\"CelebA\", x_hat[:32])), f\"{srvp_fig}/ld{ld}_{bi}.png\")\n",
    "        save_batch_images(denormalize(\"CelebA\", x_hat), f\"{srvp_fig}/ld{ld}\", bi)\n",
    "    if bi > 20:\n",
    "        break\n",
    "\n",
    "print(\"Reconstruction errors\")\n",
    "for k, v in recons_errs.items():\n",
    "    v = np.array(v)\n",
    "    print(k, np.min(v), np.mean(v), np.median(v), np.max(v))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba64dda",
   "metadata": {},
   "source": [
    "### Training a Real-vs-Fake discriminator for Generative model evaluation and Latent space traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ebd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import real_fake_discriminator, get_classifier\n",
    "\n",
    "disc_path = f\"./models/discriminators_{input_shape[-1]}/general_mid\"\n",
    "os.makedirs(disc_path, exist_ok=True)\n",
    "disc = get_classifier(\"mid\", 32, 2, device)\n",
    "real_fake_discriminator(train_dl, disc, srvps, device, disc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc016f2",
   "metadata": {},
   "source": [
    "### Sample code for finding a traversal between 2 endpoints guided by the above discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c778b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils import disc_guided_interpolation\n",
    "\n",
    "cla_type = \"deep\"\n",
    "cla_path = f\"./models/classifiers_{input_shape[-1]}/{cla_type}_{classes[0]}\"\n",
    "cla = get_classifier(cla_type, latent_dims, num_classes, device, None).to(device)\n",
    "\n",
    "srvp_disc = \"baseline\"\n",
    "srvp_path = f\"./models/SRVP_{input_shape[-1]}/cla_{cla_type}/ld{latent_dims}.tar\"\n",
    "srvp, _ = build_srvp_pipeline(device, cla, input_shape, latent_dims, \"deeper\", srvp_path)    \n",
    "\n",
    "endpts = torch.randn((2, latent_dims))\n",
    "disc_guided_interpolation(endpts, disc, srvp.decoder, device, f\"./models/discriminators_{input_shape[-1]}/general_mid.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ad80c",
   "metadata": {},
   "source": [
    "#### For the simple EDC and SRVP pipelines trained with this notebook, use the verification comparison.py script (with right constants updated at the top of the script & consistent with the 2nd cell in this notebook) to run the verification runs for these pipelines. The separation between these notebook and python script is to ease running the verification experiments on a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8392474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_exps_env",
   "language": "python",
   "name": "pytorch_exps_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
